---
title: "Import PDF Table into R"
author: "Leila"
date: "October 10, 2018"
output:
  html_document:
    toc: true
    toc_float: true
---

_Anyone who has worked with data knows that collecting it into an analyzable format is the first hurdle after a project is defined. Even for analysts who are the lucky recipients of curated, clean data, this is rarely a trivial task and can easily become a time-consuming and tedious nightmare. Luckily, since it's such a common problem, many programming angels have written helpful function packages to assist this process._

_This data import series will walk through examples which use various R packages to import data freely available online. It's intended as a beginner series, so each post will include both the minimal code snippet to complete the task at hand + an annotated version exaplaining what's going on in each line._

_I've included in the annotated segments the exploratory code used to determine how to manipulate the data into the desired format. While this intermediate exploration wouldn't appear in production code, it's an unavoidable step that will look different with each new project, so I've included it to illustrate a more complete picture of the data import process. It is not meant to represent or be confused with exploratory data analysis (the in-depth look at the data that comes after it is prepared), though the two steps often overlap._

## Task: Import PDF Data

This example uses the R library **tabulizer** for importing a dataset stored as a table in a PDF document.  It's adapted from a [tutorial by Troy Walters](https://www.r-bloggers.com/extracting-tables-from-pdfs-in-r-using-the-tabulizer-package/) on R-Bloggers. The sample data is from the California Employment Development Department, which publishes a yearly [list of layoffs](https://www.edd.ca.gov/jobs_and_training/Layoff_Services_WARN.htm) in the state of California that fall under the WARN act. The file used is the [2017-2018 Warn Report](https://www.edd.ca.gov/jobs_and_training/warn/WARN-Report-for-7-1-2017-to-06-30-2018.pdf), containing layoffs from July 1, 2017 through June 30, 2018.

The data is relatively clean to start with: the PDF is machine readable, and the data is in a table format.

## R Session Setup


```{r setup, echo = FALSE}

knitr::opts_chunk$set(echo = TRUE)
library(kableExtra) # For html formatting
library(knitr) # For html formatting

```

Load function libraries that will be used. Libraries need only be installed once, but they need to be loaded each new R session.

```{r libs, warning=FALSE}
# Load function libraries

library(tabulizer) # For reading the PDFS
library(dplyr, warn.conflicts = FALSE) # For intuitive data manipulation
library(purrr) # For combining output of each page into one table
library(janitor) # For cleaning up row name formatting

```

# TL;DR

Just the essential lines to import, clean, and export the data

```{r}
# Specify location of PDF (can be a URL or local file path)
data_url <- 'https://www.edd.ca.gov/jobs_and_training/warn/WARN-Report-for-7-1-2017-to-06-30-2018.pdf' 

# Use the extract_tables() function to scan the file and pull data tables:
output <- tabulizer::extract_tables(data_url)

# Save the first row of page 1 as a character vector:
# Subset output to the first page, first row, all columns
column_names <- output[[1]][1,] 

# Set the column names for each page and save as new list
output_named <- purrr::map(
  # Specify list object
  .x = output,
  .f = function(x) {  
    named_table <- x           
    colnames(named_table) <- column_names  
    return(named_table)   
    }) 

# Combine the list items
output_combined <- do.call(rbind, output_named) %>%  
  as.data.frame() %>%   
  slice(-1)    

# Clean col names, convert dates to dates, convert no_of_employees to a number
output_clean <- output_combined %>% 
  clean_names() %>% 
  mutate_at(.vars = c("notice_date", "effective_date", "received_date"),
            .funs = function(x) as.Date(x, format = "%m/%d/%Y")) %>% 
  mutate_at(.vars = "no_of_employees",
            .funs = as.numeric)

# All done
# Write output
write.csv(output_clean, "filename.csv")

```

Top of the table:
`r head(output_clean) %>% kable() %>% kable_styling()`

# Detailed Process Description

## PDF import

```{r import}
# Specify location of PDF (can be a URL or local file path)
data_url <- 'https://www.edd.ca.gov/jobs_and_training/warn/WARN-Report-for-7-1-2017-to-06-30-2018.pdf' 

# Use the extract_tables() function to scan the file and pull data tables:
output <- tabulizer::extract_tables(data_url)
```

### Inspect extraction output

Observations: 

* Output is a list (set of items), with one list item per page
* Each list item is a matrix with 8 columns

Observed tasks for later:

* A matrix can only have one data type, so all data was imported as character strings. Type conversion will need to be done
* The column names got imported as the first row of data on the first page

```{r check}

# What type of object?
class(output)

# How many list objects?
length(output)

# What is the type of object for each list item?
lapply(output, class) %>% 
  unlist() %>%
  unique()

# What is the data type in the matrices?
lapply(output,
       function(x) class(x[1,1])) %>% unlist() %>% 
  unique()

# What's the dimension of each list item?
lapply(output, dim) %>%
  do.call(rbind, .)

# Check that the last page loaded correctly 
# We can verify by looking at the file that this is correct
output[[length(output)]] %>%        # Subset to last list item
  head(n = 1) %>%                  # Subset to first row
  as.data.frame() %>% 
  kable() %>%           # print data as table
  kable_styling()       # format the table for html output


output[[length(output)]] %>% 
  tail(n = 1) %>% 
  as.data.frame() %>%
  kable() %>%
  kable_styling()

# Print the top and bottom 3 rows of the file

# Top of first list item
head(output[[1]], n = 3) %>% 
  as.data.frame() %>%
  kable() %>%
  kable_styling()

# Bottom of last list item
tail(output[[length(output)]], n = 3) %>% 
  as.data.frame() %>% 
  kable() %>%
  kable_styling()
```

## Organize output into an analyzable format

Tasks: 

1. Set column names (they were imported as the first row of data on page 1)
1. Combine all the pages into 1 table
1. Format the columns as necessary

### 1. Set column names

```{r getnames}
# Save the first row of page 1 as a character vector. 
# Subset output to the first page, first row, all columns
column_names <- output[[1]][1,] 

# View it
# It's messy with special characters, so it will have to be cleaned later.
column_names
```



```{r setnames}
# Set the column names for each page and save as new list
output_named <- purrr::map(
  # Specify list object
  .x = output,     
  # Write a function to set col names for each list item
  .f = function(x) {  
    # Get list item
    named_table <- x           
    # Set column names
    colnames(named_table) <- column_names  
    # Return named list item as output
    return(named_table)   
    }) 
```

### 2. Combine list items into 1 table

```{r combine}
# Combine the list items
output_combined <- do.call(rbind, output_named) %>%  
  # Convert to a data frame format
  as.data.frame() %>%   
  # Remove the first row (column names)
  slice(-1)                                      

# Inspect: What data types do we have in the columns?
# The glimpse() function lists each column, the data type, and the first few values
# All factors <fct>
glimpse(output_combined)

```

### 3. Apply formatting

```{r cleanup}

# Convert dates to dates, no_of_employees to a number
output_clean <- output_combined %>% 
  # Clean up the name syntax to be a consistent format
  clean_names() %>% 
  # Set date formats
  mutate_at(.vars = c("notice_date", "effective_date", "received_date"),
            .funs = function(x) as.Date(x, format = "%m/%d/%Y")) %>% 
  # Set numeric format
  mutate_at(.vars = "no_of_employees",
            .funs = as.numeric)

# Look at the data types after type conversion
glimpse(output_clean)

```

## Write output to csv

Unless specified otherwise, R will write to the current working directory

```{r output}
# Print path of current working directory
getwd()

# Write output
write.csv(output_clean, "filename.csv")
```


